{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "    \n",
    "import dsa\n",
    "from dsa import *\n",
    "from models import mlp\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 05:25:33.397537: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 05:25:34.650621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10545 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-04-05 05:25:34.651884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10545 MB memory:  -> device: 1, name: NVIDIA TITAN V, pci bus id: 0000:5e:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "def make_dataset(X, Y, f):\n",
    "    x = tf.data.Dataset.from_tensor_slices(X)\n",
    "    y = tf.data.Dataset.from_tensor_slices(Y)\n",
    "    x = x.map(f)\n",
    "    xy = tf.data.Dataset.zip((x, y))\n",
    "    xy = xy.shuffle(10000)\n",
    "    return xy\n",
    "\n",
    "df = pd.read_excel('../datasets/credit-card.xls', header=1, index_col=0).sample(frac=1)\n",
    "x = df.drop(columns=[\"default payment next month\"]).to_numpy()\n",
    "x = (x - np.min(x, axis=0))/(np.max(x, axis=0) - np.min(x, axis=0))\n",
    "y = df[\"default payment next month\"].to_numpy().reshape((len(x), 1)).astype(\"float32\")\n",
    "\n",
    "aux_target_ratio = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=aux_target_ratio/(aux_target_ratio+1), random_state=42)\n",
    "\n",
    "target_ds = make_dataset(x_train, y_train, lambda t: t)\n",
    "aux_ds = make_dataset(x_test, y_test, lambda t: t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "======Drop out is 0.8======\n",
      "============================\n",
      "Iteration 500, train accuracy: 0.7752064348459243, average attack MSE: 0.14693602314591409\n",
      "Iteration 1000, train accuracy: 0.7921072899103164, average attack MSE: 0.13403937710821628\n",
      "Iteration 1500, train accuracy: 0.7976067731380463, average attack MSE: 0.12233814944326878\n",
      "Iteration 2000, train accuracy: 0.8010512907505035, average attack MSE: 0.10411789274215698\n",
      "Iteration 2500, train accuracy: 0.8031949524879456, average attack MSE: 0.08426258869469166\n",
      "Iteration 3000, train accuracy: 0.8050067224502564, average attack MSE: 0.06613170708715915\n",
      "Iteration 3500, train accuracy: 0.8062579189538955, average attack MSE: 0.05115793631225824\n",
      "Iteration 4000, train accuracy: 0.8071322836875916, average attack MSE: 0.039498206440359354\n",
      "Iteration 4500, train accuracy: 0.8081291036605835, average attack MSE: 0.033107049118727444\n",
      "Iteration 5000, train accuracy: 0.8087744110822678, average attack MSE: 0.029704770810902118\n",
      "Iteration 5500, train accuracy: 0.8094312529563904, average attack MSE: 0.02816985419392586\n",
      "Iteration 6000, train accuracy: 0.8099705015420914, average attack MSE: 0.029273750357329844\n",
      "Iteration 6500, train accuracy: 0.8105669668912887, average attack MSE: 0.02872164276242256\n",
      "Iteration 7000, train accuracy: 0.8110658872127533, average attack MSE: 0.029529175195842982\n",
      "Iteration 7500, train accuracy: 0.8116568319797516, average attack MSE: 0.030356558948755264\n",
      "Iteration 8000, train accuracy: 0.8120480425357819, average attack MSE: 0.030296068582683803\n",
      "Iteration 8500, train accuracy: 0.8125170814990997, average attack MSE: 0.029867147967219353\n",
      "Iteration 9000, train accuracy: 0.8129218703508377, average attack MSE: 0.029068212587386368\n",
      "Iteration 9500, train accuracy: 0.8132236346006393, average attack MSE: 0.028284144181758165\n",
      "Iteration 10000, train accuracy: 0.8134938853979111, average attack MSE: 0.02782049822062254\n",
      "============================\n",
      "======Drop out is 0.6======\n",
      "============================\n",
      "Iteration 500, train accuracy: 0.7758421025276184, average attack MSE: 0.14077565491199492\n",
      "Iteration 1000, train accuracy: 0.7993442205190658, average attack MSE: 0.1274045141786337\n",
      "Iteration 1500, train accuracy: 0.8044435654878617, average attack MSE: 0.11233098442852497\n",
      "Iteration 2000, train accuracy: 0.8082167894840241, average attack MSE: 0.0991187956482172\n",
      "Iteration 2500, train accuracy: 0.8092528151273728, average attack MSE: 0.08560135747492313\n",
      "Iteration 3000, train accuracy: 0.8107395099401474, average attack MSE: 0.06714437610656022\n",
      "Iteration 3500, train accuracy: 0.8116006535291672, average attack MSE: 0.05154492956399918\n",
      "Iteration 4000, train accuracy: 0.8123766914606094, average attack MSE: 0.04141454815492034\n",
      "Iteration 4500, train accuracy: 0.8130845232009888, average attack MSE: 0.035566344171762465\n",
      "Iteration 5000, train accuracy: 0.813734320640564, average attack MSE: 0.03201941607147455\n",
      "Iteration 5500, train accuracy: 0.8142698675394058, average attack MSE: 0.03057205970212817\n",
      "Iteration 6000, train accuracy: 0.8144685717821121, average attack MSE: 0.030542581524699925\n",
      "Iteration 6500, train accuracy: 0.8149105724096298, average attack MSE: 0.030641351718455553\n",
      "Iteration 7000, train accuracy: 0.8151214323043823, average attack MSE: 0.02996938532218337\n",
      "Iteration 7500, train accuracy: 0.8152764358520508, average attack MSE: 0.029761089384555815\n",
      "Iteration 8000, train accuracy: 0.8155215910673141, average attack MSE: 0.028462071970105172\n",
      "Iteration 8500, train accuracy: 0.8157178447246551, average attack MSE: 0.028022600904107093\n",
      "Iteration 9000, train accuracy: 0.8160111278295517, average attack MSE: 0.027131617326289416\n",
      "Iteration 9500, train accuracy: 0.816203036904335, average attack MSE: 0.027680179353803396\n",
      "Iteration 10000, train accuracy: 0.8164590847492218, average attack MSE: 0.027056202515959738\n",
      "============================\n",
      "======Drop out is 0.4======\n",
      "============================\n",
      "Iteration 500, train accuracy: 0.7884399778842927, average attack MSE: 0.13985896573960782\n",
      "Iteration 1000, train accuracy: 0.802038854598999, average attack MSE: 0.12291538558900356\n",
      "Iteration 1500, train accuracy: 0.8075847707986832, average attack MSE: 0.10314389967918396\n",
      "Iteration 2000, train accuracy: 0.8093027983903884, average attack MSE: 0.08803568367660046\n",
      "Iteration 2500, train accuracy: 0.8108676145076752, average attack MSE: 0.07381018473207951\n",
      "Iteration 3000, train accuracy: 0.8122307118177414, average attack MSE: 0.058586399115622044\n",
      "Iteration 3500, train accuracy: 0.8135184531211853, average attack MSE: 0.0470087900981307\n",
      "Iteration 4000, train accuracy: 0.8140408133268356, average attack MSE: 0.039133431326597926\n",
      "Iteration 4500, train accuracy: 0.8148302364349366, average attack MSE: 0.03351777878776192\n",
      "Iteration 5000, train accuracy: 0.8150496131181717, average attack MSE: 0.029840489756315945\n",
      "Iteration 5500, train accuracy: 0.8154977347850799, average attack MSE: 0.027766527391970157\n",
      "Iteration 6000, train accuracy: 0.8161203228235244, average attack MSE: 0.026641964506357908\n",
      "Iteration 6500, train accuracy: 0.8163448913097382, average attack MSE: 0.026259098451584577\n",
      "Iteration 7000, train accuracy: 0.8165894786119461, average attack MSE: 0.02589105048775673\n",
      "Iteration 7500, train accuracy: 0.8166177982091903, average attack MSE: 0.026029188498854636\n",
      "Iteration 8000, train accuracy: 0.8168457945585251, average attack MSE: 0.025743882581591607\n",
      "Iteration 8500, train accuracy: 0.8170638531446457, average attack MSE: 0.026105021871626378\n",
      "Iteration 9000, train accuracy: 0.8173087521791458, average attack MSE: 0.02569130077213049\n",
      "Iteration 9500, train accuracy: 0.8175175873041153, average attack MSE: 0.025196074172854424\n",
      "Iteration 10000, train accuracy: 0.8176599912643433, average attack MSE: 0.024885906044393776\n",
      "============================\n",
      "======Drop out is 0.2======\n",
      "============================\n",
      "Iteration 500, train accuracy: 0.7889394686222077, average attack MSE: 0.13735087503492832\n",
      "Iteration 1000, train accuracy: 0.801838759303093, average attack MSE: 0.12074506877362728\n",
      "Iteration 1500, train accuracy: 0.8078023290634155, average attack MSE: 0.10140401259064674\n",
      "Iteration 2000, train accuracy: 0.8102219904661179, average attack MSE: 0.08041667805612088\n",
      "Iteration 2500, train accuracy: 0.8118899188041687, average attack MSE: 0.06573034523427486\n",
      "Iteration 3000, train accuracy: 0.812801560997963, average attack MSE: 0.05202285645157099\n",
      "Iteration 3500, train accuracy: 0.8136420248746872, average attack MSE: 0.04206635060161352\n",
      "Iteration 4000, train accuracy: 0.8142686287164688, average attack MSE: 0.03476619533449411\n",
      "Iteration 4500, train accuracy: 0.815012116074562, average attack MSE: 0.030667598370462654\n",
      "Iteration 5000, train accuracy: 0.8153920712471008, average attack MSE: 0.028890135049819948\n",
      "Iteration 5500, train accuracy: 0.8157308926582336, average attack MSE: 0.02826842596754432\n",
      "Iteration 6000, train accuracy: 0.816132854104042, average attack MSE: 0.0282594021782279\n",
      "Iteration 6500, train accuracy: 0.8166000655889512, average attack MSE: 0.02837266183644533\n",
      "Iteration 7000, train accuracy: 0.8170202490091324, average attack MSE: 0.028319704577326774\n",
      "Iteration 7500, train accuracy: 0.8171261699199677, average attack MSE: 0.028294648341834545\n",
      "Iteration 8000, train accuracy: 0.8174464899301529, average attack MSE: 0.028393510330468417\n",
      "Iteration 8500, train accuracy: 0.8177380571365357, average attack MSE: 0.027854221571236848\n",
      "Iteration 9000, train accuracy: 0.8179731612205505, average attack MSE: 0.02796830066666007\n",
      "Iteration 9500, train accuracy: 0.8181027241945267, average attack MSE: 0.026221924688667058\n",
      "Iteration 10000, train accuracy: 0.8182702087163926, average attack MSE: 0.025108051151037217\n"
     ]
    }
   ],
   "source": [
    "credit_dsa_dropout = {}\n",
    "log_credit_dsa_dropout = {}\n",
    "\n",
    "for dropout in [0.8,0.6,0.4,0.2]:\n",
    "    make_f, make_g, make_e, make_d, make_c = mlp.make_mlp(attr_num=23, class_num=2, split=3, units=64, ed_act=\"relu\", dropout=dropout)\n",
    "    credit_dsa_dropout[dropout] = dsa(target_ds=target_ds, aux_ds=aux_ds)\n",
    "    print(\"============================\")\n",
    "    print(\"======Drop out is {}======\".format(dropout))\n",
    "    print(\"============================\")\n",
    "    log_credit_dsa_dropout[dropout] = credit_dsa_dropout[dropout].dsa_attack(\n",
    "        make_f=make_f,\n",
    "        make_g=make_g,\n",
    "        lr=0.001,\n",
    "        loss_fn=tf.keras.losses.BinaryCrossentropy(),\n",
    "        acc_fn=tf.keras.metrics.BinaryAccuracy(),\n",
    "        batch_size=32,\n",
    "        iterations=10000,\n",
    "        make_e=make_e,\n",
    "        make_d=make_d,\n",
    "        make_c=make_c,\n",
    "        lr_e=0.00001, # learning rate of the encoder/decoder/critic is set to be smaller\n",
    "        lr_d=0.00001,\n",
    "        lr_c=0.0001,\n",
    "        verbose=True,\n",
    "        log_freq=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log/credit-dsa-dropout.pkl', 'wb') as f:\n",
    "    pickle.dump(log_credit_dsa_dropout, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log/credit-dsa.pkl', 'rb') as f:\n",
    "    log0 = pickle.load(f)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sampled_loss = {}\n",
    "\n",
    "log_freq = 200\n",
    "for dropout in [0.8,0.6,0.4,0.2]:\n",
    "    sampled_loss[dropout] = [sum(log_credit_dsa_dropout[dropout][:,2][i*log_freq:(i+1)*log_freq])/log_freq for i in range(int(len(log_credit_dsa_dropout[dropout][:,0])/log_freq))]\n",
    "sampled_loss[0] = [sum(log0[:,2][i*log_freq:(i+1)*log_freq])/log_freq for i in range(int(len(log0[:,0])/log_freq))]\n",
    "\n",
    "x = [\"0.0\", '0.2', '0.4', '0.6', '0.8']\n",
    "y = [sampled_loss[i][-1] for i in [0,0.2,0.4,0.6,0.8]]\n",
    "plt.xlabel(\"Dropout rate\")\n",
    "plt.ylabel(\"MSE per feature\")\n",
    "plt.bar(x, y, color='b', width=0.5)\n",
    "plt.plot(x,y,'gs-')\n",
    "plt.savefig(\"fig/dsa-dropout.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
